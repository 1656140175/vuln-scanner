---
task_id: 003
title: "基础测试框架搭建"
phase: 1
priority: high
estimated_effort: 1.5d
parallel: true
dependencies: ["001"]
assignee: "test-engineer"
tags: ["testing", "pytest", "coverage", "infrastructure"]
---

# Task 003: 基础测试框架搭建 🧪

## 概述
建立完整的自动化测试基础设施，包括单元测试、集成测试、覆盖率监控和测试数据管理，为VulnMiner v2提供90%+的测试覆盖率保障。

## 背景与目标
当前系统缺乏完整的测试框架，需要建立：
1. **分层测试架构**: 单元测试、集成测试、端到端测试
2. **高覆盖率**: 目标90%+代码覆盖率
3. **自动化执行**: CI/CD集成和自动化测试
4. **测试数据管理**: Mock数据和测试环境

## 技术架构

### 1. 测试目录结构
```
vuln_scanner/tests/
├── unit/                    # 单元测试
│   ├── core/               # 核心模块测试
│   │   ├── test_config.py
│   │   ├── test_scanner.py
│   │   └── test_ai.py
│   ├── tools/              # 工具模块测试
│   └── platforms/          # 平台模块测试
├── integration/            # 集成测试
│   ├── test_scan_pipeline.py
│   ├── test_ai_integration.py
│   └── test_tool_chain.py
├── e2e/                   # 端到端测试
│   ├── test_full_scan.py
│   └── test_user_workflow.py
├── fixtures/              # 测试数据
│   ├── configs/           # 测试配置文件
│   ├── scan_results/      # 模拟扫描结果
│   └── targets/           # 测试目标数据
├── mocks/                 # Mock对象
│   ├── mock_tools.py
│   ├── mock_ai.py
│   └── mock_platforms.py
└── conftest.py           # pytest配置
```

### 2. 测试技术栈
- **测试框架**: pytest + pytest-asyncio
- **覆盖率工具**: coverage.py + pytest-cov
- **Mock框架**: unittest.mock + pytest-mock
- **测试数据**: factory-boy + faker
- **并发测试**: pytest-xdist
- **报告生成**: pytest-html + allure

## 实施步骤

### Step 1: 测试基础设施 (0.5天)

#### 1.1 pytest配置
```python
# vuln_scanner/tests/conftest.py
import pytest
import asyncio
import tempfile
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock

@pytest.fixture(scope="session")
def event_loop():
    """创建事件循环"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def temp_config_dir():
    """临时配置目录"""
    with tempfile.TemporaryDirectory() as temp_dir:
        yield Path(temp_dir)

@pytest.fixture
def mock_config():
    """模拟配置对象"""
    from vuln_scanner.core.config.models import VulnMinerConfig, AIConfig
    
    config = VulnMinerConfig()
    config.ai = AIConfig(enabled=True, default_provider="mock")
    return config

@pytest.fixture
def mock_ai_provider():
    """模拟AI提供商"""
    mock = AsyncMock()
    mock.analyze_vulnerability.return_value = {
        "severity": "high",
        "confidence": 0.95,
        "description": "Mock vulnerability analysis"
    }
    return mock

@pytest.fixture
def sample_scan_target():
    """示例扫描目标"""
    return {
        "url": "https://example.com",
        "type": "web",
        "scope": "subdomain"
    }
```

#### 1.2 测试配置文件
```ini
# vuln_scanner/pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --cov=vuln_scanner
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=90
    --asyncio-mode=auto
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    slow: Slow running tests
    network: Tests requiring network access
    ai: Tests involving AI providers
asyncio_mode = auto
```

### Step 2: 核心模块测试 (0.5天)

#### 2.1 配置管理测试
```python
# vuln_scanner/tests/unit/core/test_config.py
import pytest
import os
from pathlib import Path
from vuln_scanner.core.config import ConfigManager
from vuln_scanner.core.config.models import VulnMinerConfig

class TestConfigManager:
    """配置管理器测试"""
    
    def test_load_default_config(self):
        """测试加载默认配置"""
        config_manager = ConfigManager()
        config = config_manager.get_config()
        
        assert isinstance(config, VulnMinerConfig)
        assert config.ai.enabled is True
        assert len(config.ai.providers) > 0
    
    def test_env_var_substitution(self, monkeypatch, temp_config_dir):
        """测试环境变量替换"""
        # 设置环境变量
        monkeypatch.setenv("TEST_API_KEY", "test-key-123")
        
        # 创建测试配置
        config_content = """
        ai:
          providers:
            test:
              api_key: "${TEST_API_KEY}"
              base_url: "${TEST_BASE_URL:http://localhost:8080}"
        """
        
        config_file = temp_config_dir / "test.yml"
        config_file.write_text(config_content)
        
        config_manager = ConfigManager(str(config_file))
        config = config_manager.get_config()
        
        assert config.ai.providers["test"].api_key == "test-key-123"
        assert config.ai.providers["test"].base_url == "http://localhost:8080"
    
    def test_config_validation(self):
        """测试配置验证"""
        config_manager = ConfigManager()
        errors = config_manager.validate()
        
        # 默认配置应该是有效的
        assert len(errors) == 0
    
    @pytest.mark.parametrize("provider,expected_error", [
        ("openai", "缺少API密钥"),
        ("claude", "缺少API密钥"),
    ])
    def test_ai_config_validation(self, provider, expected_error):
        """测试AI配置验证"""
        # 测试缺少API密钥的情况
        pass
```

#### 2.2 AI集成测试
```python
# vuln_scanner/tests/unit/core/test_ai.py
import pytest
from unittest.mock import AsyncMock, patch
from vuln_scanner.core.ai import AIManager, OpenAIProvider

class TestAIManager:
    """AI管理器测试"""
    
    @pytest.fixture
    def ai_manager(self, mock_config):
        """AI管理器实例"""
        return AIManager(mock_config.ai)
    
    @pytest.mark.asyncio
    async def test_provider_selection(self, ai_manager):
        """测试AI提供商选择"""
        provider = ai_manager.get_provider("openai")
        assert provider is not None
    
    @pytest.mark.asyncio
    async def test_fallback_mechanism(self, ai_manager):
        """测试故障转移机制"""
        # 模拟第一个提供商失败
        with patch.object(ai_manager.providers["openai"], "analyze", side_effect=Exception("API Error")):
            result = await ai_manager.analyze_findings([])
            # 应该使用备用提供商或传统分析
            assert result is not None

class TestOpenAIProvider:
    """OpenAI提供商测试"""
    
    @pytest.mark.asyncio
    @patch("openai.ChatCompletion.acreate")
    async def test_vulnerability_analysis(self, mock_openai):
        """测试漏洞分析"""
        # 模拟OpenAI响应
        mock_openai.return_value = {
            "choices": [{
                "message": {
                    "content": '{"severity": "high", "confidence": 0.95}'
                }
            }]
        }
        
        provider = OpenAIProvider(api_key="test", base_url="http://test")
        result = await provider.analyze_vulnerability({"type": "sql_injection"})
        
        assert result["severity"] == "high"
        assert result["confidence"] == 0.95
```

### Step 3: 集成测试 (0.3天)

#### 3.1 扫描流程集成测试
```python
# vuln_scanner/tests/integration/test_scan_pipeline.py
import pytest
from vuln_scanner.core.scanner import ScanEngine
from vuln_scanner.core.config import ConfigManager

class TestScanPipeline:
    """扫描管道集成测试"""
    
    @pytest.fixture
    def scan_engine(self):
        """扫描引擎实例"""
        config = ConfigManager().get_config()
        return ScanEngine(config)
    
    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_quick_scan_pipeline(self, scan_engine, sample_scan_target):
        """测试快速扫描管道"""
        result = await scan_engine.run_quick_scan(sample_scan_target)
        
        assert result is not None
        assert "findings" in result
        assert "metadata" in result
        assert result["status"] == "completed"
    
    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.slow
    async def test_comprehensive_scan_pipeline(self, scan_engine, sample_scan_target):
        """测试全面扫描管道"""
        result = await scan_engine.run_comprehensive_scan(sample_scan_target)
        
        assert result is not None
        assert len(result["findings"]) >= 0
        assert result["scan_time"] > 0
```

### Step 4: 测试工具和报告 (0.2天)

#### 4.1 测试运行脚本
```python
# vuln_scanner/scripts/run_tests.py
#!/usr/bin/env python3
"""测试运行脚本"""
import sys
import subprocess
from pathlib import Path

def run_unit_tests():
    """运行单元测试"""
    cmd = ["python", "-m", "pytest", "tests/unit/", "-v", "--cov=vuln_scanner"]
    return subprocess.run(cmd).returncode

def run_integration_tests():
    """运行集成测试"""
    cmd = ["python", "-m", "pytest", "tests/integration/", "-v", "-m", "integration"]
    return subprocess.run(cmd).returncode

def run_all_tests():
    """运行所有测试"""
    cmd = ["python", "-m", "pytest", "tests/", "-v"]
    return subprocess.run(cmd).returncode

def generate_coverage_report():
    """生成覆盖率报告"""
    cmd = ["python", "-m", "coverage", "html", "--directory=htmlcov"]
    subprocess.run(cmd)
    print("📊 覆盖率报告生成完成: htmlcov/index.html")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        test_type = sys.argv[1]
        if test_type == "unit":
            exit_code = run_unit_tests()
        elif test_type == "integration":
            exit_code = run_integration_tests()
        elif test_type == "all":
            exit_code = run_all_tests()
        else:
            print("❌ 未知的测试类型。使用: unit, integration, all")
            sys.exit(1)
    else:
        exit_code = run_all_tests()
    
    if exit_code == 0:
        generate_coverage_report()
    
    sys.exit(exit_code)
```

#### 4.2 测试数据工厂
```python
# vuln_scanner/tests/factories.py
import factory
from faker import Faker
from vuln_scanner.core.models import ScanTarget, Finding, Vulnerability

fake = Faker()

class ScanTargetFactory(factory.Factory):
    """扫描目标工厂"""
    class Meta:
        model = ScanTarget
    
    url = factory.LazyFunction(lambda: fake.url())
    target_type = "web"
    scope = "subdomain"

class FindingFactory(factory.Factory):
    """发现结果工厂"""
    class Meta:
        model = Finding
    
    title = factory.LazyFunction(lambda: fake.sentence())
    severity = factory.Iterator(["critical", "high", "medium", "low"])
    confidence = factory.LazyFunction(lambda: fake.pyfloat(min_value=0.1, max_value=1.0))
    description = factory.LazyFunction(lambda: fake.text())

class VulnerabilityFactory(factory.Factory):
    """漏洞工厂"""
    class Meta:
        model = Vulnerability
    
    cve_id = factory.LazyFunction(lambda: f"CVE-{fake.year()}-{fake.random_int(1000, 9999)}")
    cvss_score = factory.LazyFunction(lambda: fake.pyfloat(min_value=0.0, max_value=10.0))
    category = factory.Iterator(["sql_injection", "xss", "csrf", "rce"])
```

## 验收标准

### 测试覆盖率验收
- [ ] **单元测试覆盖率**: ≥ 90%
- [ ] **集成测试覆盖**: 主要业务流程100%覆盖
- [ ] **关键路径测试**: 扫描流程端到端测试
- [ ] **错误处理测试**: 异常情况覆盖

### 测试质量验收
- [ ] **测试速度**: 单元测试 < 30秒，全量测试 < 5分钟
- [ ] **测试稳定性**: 连续运行10次无随机失败
- [ ] **测试独立性**: 测试间无依赖，可并行执行
- [ ] **Mock质量**: 外部依赖100% Mock

### 自动化验收
```bash
# 运行测试套件
python scripts/run_tests.py all

# 检查覆盖率
coverage report --show-missing

# 运行特定标记的测试
pytest -m "unit and not slow"
pytest -m "integration"
pytest -m "ai"
```

## 交付物

### 测试基础设施
- [ ] pytest配置和插件集成
- [ ] 测试目录结构和规范
- [ ] Mock框架和测试数据工厂
- [ ] 覆盖率监控和报告生成

### 测试用例
- [ ] 核心模块单元测试（90%+覆盖率）
- [ ] 业务流程集成测试
- [ ] AI集成测试和Mock
- [ ] 配置管理测试

### 测试工具
- [ ] 自动化测试运行脚本
- [ ] 测试数据生成工具
- [ ] 测试报告生成器
- [ ] CI/CD集成配置

### 文档
- [ ] 测试框架使用指南
- [ ] 测试编写规范
- [ ] Mock和测试数据指南
- [ ] 测试调试手册

## 风险与缓解

### 技术风险
1. **异步测试复杂性**: pytest-asyncio配置和调试困难
   - **缓解**: 详细的异步测试示例和文档
   - **工具**: 使用pytest-asyncio auto模式

2. **Mock复杂性**: 复杂业务逻辑的Mock设计困难
   - **缓解**: 分层Mock策略，从简单到复杂
   - **最佳实践**: Mock外部依赖，不Mock业务逻辑

### 质量风险
1. **测试维护成本**: 测试代码量可能超过业务代码
   - **缓解**: 重点测试核心业务逻辑
   - **策略**: 测试金字塔原则，更多单元测试

---
**任务负责人**: Test Engineer  
**审核人**: Tech Lead  
**依赖任务**: Task 001 (代码目录重构)  
**并行任务**: Task 002 (配置管理系统)  
**预计工作量**: 1.5天