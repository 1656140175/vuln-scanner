---
task_id: 004
title: "AI LLMs适配器实现"
phase: 2
priority: high
estimated_effort: 3d
parallel: false
dependencies: ["001", "002"]
assignee: "ai-engineer"
tags: ["ai", "llm", "integration", "openai", "claude"]
---

# Task 004: AI LLMs适配器实现 🤖

## 概述
实现多AI提供商适配器架构，支持OpenAI、Claude、Ollama等主流LLMs，提供统一的AI分析接口，为VulnMiner添加智能漏洞分析和报告生成能力。

## 背景与目标
将AI能力集成到VulnMiner中，实现：
1. **多提供商支持**: OpenAI GPT-4、Claude 3、Ollama本地模型
2. **智能分析**: 漏洞验证、风险评估、误报过滤
3. **故障转移**: 自动切换备用提供商
4. **成本控制**: Token使用优化和费用监控

## 技术架构

### 1. 适配器模式设计
```
AIManager (管理器)
├── OpenAIProvider (OpenAI适配器)
├── ClaudeProvider (Claude适配器)  
├── OllamaProvider (Ollama适配器)
└── MockProvider (测试适配器)

每个适配器实现统一接口：
- analyze_vulnerability() - 漏洞分析
- generate_report() - 报告生成
- classify_risk() - 风险分类
- filter_false_positives() - 误报过滤
```

### 2. AI功能模块
- **漏洞分析**: 深度分析扫描结果，提供专业解释
- **风险评估**: 基于上下文的CVSS评分和风险等级
- **报告优化**: 生成专业的漏洞报告和修复建议
- **误报过滤**: 智能识别和过滤误报结果

## 实施步骤

### Step 1: 核心接口和基类 (0.5天)

#### 1.1 AI提供商基类
```python
# vuln_scanner/core/ai/base.py
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class RiskLevel(Enum):
    """风险等级枚举"""
    CRITICAL = "critical"
    HIGH = "high" 
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class VulnerabilityAnalysis:
    """漏洞分析结果"""
    severity: RiskLevel
    confidence: float  # 0.0-1.0
    cvss_score: Optional[float]
    description: str
    impact: str
    remediation: str
    false_positive_probability: float
    references: List[str]

@dataclass
class AIProviderConfig:
    """AI提供商配置"""
    name: str
    api_key: Optional[str]
    base_url: str
    model: str
    timeout: int = 30
    max_tokens: int = 4000
    temperature: float = 0.1

class AIProvider(ABC):
    """AI提供商基类"""
    
    def __init__(self, config: AIProviderConfig):
        self.config = config
        self.name = config.name
        
    @abstractmethod
    async def analyze_vulnerability(self, finding: Dict[str, Any]) -> VulnerabilityAnalysis:
        """分析单个漏洞发现"""
        pass
    
    @abstractmethod 
    async def generate_report_summary(self, findings: List[Dict[str, Any]]) -> str:
        """生成报告摘要"""
        pass
    
    @abstractmethod
    async def classify_risk(self, vulnerability: Dict[str, Any]) -> RiskLevel:
        """风险分类"""
        pass
    
    @abstractmethod
    async def filter_false_positives(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """过滤误报"""
        pass
    
    @abstractmethod
    async def health_check(self) -> bool:
        """健康检查"""
        pass
```

#### 1.2 AI管理器核心
```python
# vuln_scanner/core/ai/manager.py
import logging
from typing import Dict, List, Optional, Type
from .base import AIProvider, VulnerabilityAnalysis, RiskLevel
from .providers import OpenAIProvider, ClaudeProvider, OllamaProvider
from ..config.models import AIConfig

class AIManager:
    """AI服务管理器 - 统一管理多个AI提供商"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.providers: Dict[str, AIProvider] = {}
        self.fallback_order = config.fallback_order
        
        # 初始化提供商
        self._initialize_providers()
    
    def _initialize_providers(self):
        """初始化AI提供商"""
        provider_classes = {
            "openai": OpenAIProvider,
            "claude": ClaudeProvider, 
            "ollama": OllamaProvider
        }
        
        for provider_name, provider_config in self.config.providers.items():
            if provider_name in provider_classes:
                try:
                    provider_class = provider_classes[provider_name]
                    provider = provider_class(provider_config)
                    self.providers[provider_name] = provider
                    self.logger.info(f"✅ AI提供商 {provider_name} 初始化成功")
                except Exception as e:
                    self.logger.error(f"❌ AI提供商 {provider_name} 初始化失败: {e}")
    
    async def analyze_vulnerability(self, finding: Dict[str, Any]) -> Optional[VulnerabilityAnalysis]:
        """使用AI分析漏洞（带故障转移）"""
        for provider_name in self.fallback_order:
            if provider_name not in self.providers:
                continue
                
            try:
                provider = self.providers[provider_name]
                result = await provider.analyze_vulnerability(finding)
                self.logger.info(f"✅ 使用 {provider_name} 完成漏洞分析")
                return result
            except Exception as e:
                self.logger.warning(f"⚠️ AI提供商 {provider_name} 分析失败: {e}")
                continue
        
        # 所有AI提供商都失败，使用传统规则分析
        self.logger.warning("所有AI提供商失败，使用传统规则分析")
        return self._fallback_analysis(finding)
    
    def _fallback_analysis(self, finding: Dict[str, Any]) -> VulnerabilityAnalysis:
        """传统规则分析（AI故障时的备选方案）"""
        # 基于规则的简单分析
        severity = self._rule_based_severity(finding)
        
        return VulnerabilityAnalysis(
            severity=severity,
            confidence=0.7,  # 规则分析置信度较低
            cvss_score=None,
            description=f"基于规则分析的 {finding.get('type', 'unknown')} 漏洞",
            impact="需要人工确认影响程度",
            remediation="请参考标准安全指南进行修复",
            false_positive_probability=0.3,
            references=[]
        )
```

### Step 2: OpenAI适配器实现 (1天)

#### 2.1 OpenAI提供商
```python
# vuln_scanner/core/ai/providers/openai_provider.py
import asyncio
import openai
from typing import Dict, List, Any
from ..base import AIProvider, VulnerabilityAnalysis, RiskLevel, AIProviderConfig

class OpenAIProvider(AIProvider):
    """OpenAI GPT提供商"""
    
    def __init__(self, config: AIProviderConfig):
        super().__init__(config)
        openai.api_key = config.api_key
        if config.base_url:
            openai.api_base = config.base_url
    
    async def analyze_vulnerability(self, finding: Dict[str, Any]) -> VulnerabilityAnalysis:
        """使用GPT分析漏洞"""
        prompt = self._create_vulnerability_prompt(finding)
        
        try:
            response = await openai.ChatCompletion.acreate(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.config.max_tokens,
                temperature=self.config.temperature,
                timeout=self.config.timeout
            )
            
            analysis_text = response.choices[0].message.content
            return self._parse_analysis_response(analysis_text)
            
        except Exception as e:
            self.logger.error(f"OpenAI API调用失败: {e}")
            raise
    
    def _get_system_prompt(self) -> str:
        """获取系统提示词"""
        return """你是一个专业的网络安全专家，负责分析漏洞扫描结果。

请按照以下格式分析漏洞：
1. 风险等级 (critical/high/medium/low/info)
2. 置信度 (0.0-1.0)
3. CVSS评分 (0.0-10.0)
4. 详细描述
5. 影响分析
6. 修复建议
7. 误报概率 (0.0-1.0)
8. 相关参考

使用JSON格式回复，确保专业性和准确性。考虑中文用户的理解习惯。"""
    
    def _create_vulnerability_prompt(self, finding: Dict[str, Any]) -> str:
        """创建漏洞分析提示词"""
        return f"""
请分析以下漏洞扫描结果：

扫描工具: {finding.get('tool', 'unknown')}
目标: {finding.get('target', 'unknown')}
漏洞类型: {finding.get('type', 'unknown')}
发现详情: {finding.get('details', 'N/A')}
原始输出: {finding.get('raw_output', 'N/A')}

请提供专业的漏洞分析，包括风险评估和修复建议。
"""
    
    def _parse_analysis_response(self, response_text: str) -> VulnerabilityAnalysis:
        """解析AI响应为结构化数据"""
        try:
            import json
            data = json.loads(response_text)
            
            return VulnerabilityAnalysis(
                severity=RiskLevel(data.get('severity', 'medium')),
                confidence=float(data.get('confidence', 0.8)),
                cvss_score=data.get('cvss_score'),
                description=data.get('description', ''),
                impact=data.get('impact', ''),
                remediation=data.get('remediation', ''),
                false_positive_probability=float(data.get('false_positive_probability', 0.1)),
                references=data.get('references', [])
            )
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # 如果解析失败，返回基础分析
            return VulnerabilityAnalysis(
                severity=RiskLevel.MEDIUM,
                confidence=0.6,
                cvss_score=None,
                description=response_text[:500],  # 截取前500字符
                impact="需要人工验证",
                remediation="请参考安全最佳实践",
                false_positive_probability=0.2,
                references=[]
            )
    
    async def generate_report_summary(self, findings: List[Dict[str, Any]]) -> str:
        """生成报告摘要"""
        summary_prompt = f"""
基于以下扫描结果生成专业的安全评估报告摘要：

扫描发现数量: {len(findings)}
发现类型: {list(set(f.get('type', 'unknown') for f in findings))}

请生成一个简洁而专业的摘要，包括：
1. 总体安全状况
2. 主要风险点
3. 优先修复建议
4. 整体风险评级

用中文回复，保持专业性。
"""
        
        try:
            response = await openai.ChatCompletion.acreate(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": "你是一个网络安全专家，负责撰写专业的安全评估报告。"},
                    {"role": "user", "content": summary_prompt}
                ],
                max_tokens=1000,
                temperature=0.1
            )
            
            return response.choices[0].message.content
        except Exception as e:
            return f"报告摘要生成失败: {e}"
    
    async def health_check(self) -> bool:
        """健康检查"""
        try:
            await openai.ChatCompletion.acreate(
                model=self.config.model,
                messages=[{"role": "user", "content": "ping"}],
                max_tokens=10,
                timeout=5
            )
            return True
        except Exception:
            return False
```

### Step 3: Claude适配器实现 (1天)

#### 3.1 Claude提供商
```python
# vuln_scanner/core/ai/providers/claude_provider.py
import asyncio
import anthropic
from typing import Dict, List, Any
from ..base import AIProvider, VulnerabilityAnalysis, RiskLevel, AIProviderConfig

class ClaudeProvider(AIProvider):
    """Claude AI提供商"""
    
    def __init__(self, config: AIProviderConfig):
        super().__init__(config)
        self.client = anthropic.AsyncAnthropic(
            api_key=config.api_key,
            base_url=config.base_url if config.base_url else None
        )
    
    async def analyze_vulnerability(self, finding: Dict[str, Any]) -> VulnerabilityAnalysis:
        """使用Claude分析漏洞"""
        prompt = self._create_vulnerability_prompt(finding)
        
        try:
            message = await self.client.messages.create(
                model=self.config.model,
                max_tokens=self.config.max_tokens,
                temperature=self.config.temperature,
                system=self._get_system_prompt(),
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            analysis_text = message.content[0].text
            return self._parse_analysis_response(analysis_text)
            
        except Exception as e:
            self.logger.error(f"Claude API调用失败: {e}")
            raise
    
    def _get_system_prompt(self) -> str:
        """获取系统提示词"""
        return """你是一位经验丰富的网络安全专家，专门负责分析漏洞扫描结果。

分析任务要求：
1. 准确评估漏洞的真实风险等级
2. 考虑实际环境中的可利用性
3. 提供具体可行的修复方案
4. 识别可能的误报情况

请使用JSON格式回复，包含以下字段：
- severity: critical/high/medium/low/info
- confidence: 0.0-1.0 (分析置信度)
- cvss_score: 0.0-10.0 (CVSS v3评分)
- description: 详细的漏洞描述
- impact: 潜在影响分析
- remediation: 具体修复建议
- false_positive_probability: 0.0-1.0 (误报概率)
- references: 相关参考资料列表

确保分析的专业性和实用性。"""
    
    async def generate_report_summary(self, findings: List[Dict[str, Any]]) -> str:
        """生成报告摘要"""
        findings_summary = self._create_findings_summary(findings)
        
        prompt = f"""
请基于以下漏洞扫描结果生成一份专业的安全评估报告摘要：

{findings_summary}

报告摘要应包括：
1. 安全状况总览
2. 关键风险识别
3. 修复优先级建议
4. 整体安全评级

请用简洁专业的中文撰写，适合向技术和管理层汇报。
"""
        
        try:
            message = await self.client.messages.create(
                model=self.config.model,
                max_tokens=1000,
                temperature=0.1,
                system="你是一名资深的网络安全顾问，负责为客户撰写专业的安全评估报告。",
                messages=[{"role": "user", "content": prompt}]
            )
            
            return message.content[0].text
        except Exception as e:
            return f"使用Claude生成报告摘要失败: {e}"
    
    def _create_findings_summary(self, findings: List[Dict[str, Any]]) -> str:
        """创建发现摘要"""
        if not findings:
            return "未发现安全问题"
        
        severity_counts = {}
        for finding in findings:
            severity = finding.get('severity', 'unknown')
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        summary = f"总计发现 {len(findings)} 个安全问题：\n"
        for severity, count in severity_counts.items():
            summary += f"- {severity}: {count}个\n"
        
        return summary
```

### Step 4: Ollama本地模型支持 (0.5天)

#### 4.1 Ollama提供商
```python
# vuln_scanner/core/ai/providers/ollama_provider.py
import aiohttp
import asyncio
from typing import Dict, List, Any
from ..base import AIProvider, VulnerabilityAnalysis, RiskLevel, AIProviderConfig

class OllamaProvider(AIProvider):
    """Ollama本地模型提供商"""
    
    def __init__(self, config: AIProviderConfig):
        super().__init__(config)
        self.base_url = config.base_url.rstrip('/')
        
    async def analyze_vulnerability(self, finding: Dict[str, Any]) -> VulnerabilityAnalysis:
        """使用Ollama本地模型分析漏洞"""
        prompt = self._create_vulnerability_prompt(finding)
        
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.config.model,
                    "prompt": prompt,
                    "system": self._get_system_prompt(),
                    "stream": False,
                    "options": {
                        "temperature": self.config.temperature,
                        "num_predict": self.config.max_tokens
                    }
                }
                
                async with session.post(
                    f"{self.base_url}/api/generate",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.config.timeout)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        analysis_text = result.get('response', '')
                        return self._parse_analysis_response(analysis_text)
                    else:
                        raise Exception(f"Ollama API返回错误状态: {response.status}")
                        
        except Exception as e:
            self.logger.error(f"Ollama API调用失败: {e}")
            raise
    
    async def health_check(self) -> bool:
        """检查Ollama服务状态"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.base_url}/api/tags",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    return response.status == 200
        except Exception:
            return False
```

## 验收标准

### 功能性验收
- [ ] **多提供商支持**: OpenAI、Claude、Ollama全部可用
- [ ] **统一接口**: 所有提供商实现相同的API接口
- [ ] **故障转移**: 主提供商失败时自动切换
- [ ] **配置灵活**: 支持base_url等参数配置

### AI功能验收
```python
# AI功能测试
ai_manager = AIManager(config.ai)

# 漏洞分析测试
finding = {"type": "sql_injection", "target": "https://example.com"}
analysis = await ai_manager.analyze_vulnerability(finding)
assert analysis.severity in [RiskLevel.HIGH, RiskLevel.CRITICAL]
assert analysis.confidence > 0.8

# 报告生成测试
summary = await ai_manager.generate_report_summary([finding])
assert len(summary) > 100
assert "SQL注入" in summary or "sql injection" in summary.lower()
```

### 性能验收
- [ ] **响应时间**: 单次分析 < 30秒
- [ ] **并发处理**: 支持3个并发分析请求
- [ ] **错误恢复**: API失败后能自动重试
- [ ] **成本控制**: Token使用量监控

## 交付物

### 核心代码
- [ ] AI提供商基类和接口定义
- [ ] OpenAI适配器完整实现
- [ ] Claude适配器完整实现
- [ ] Ollama适配器实现
- [ ] AI管理器和故障转移逻辑

### 配置和工具
- [ ] AI提供商配置模板
- [ ] API密钥管理方案
- [ ] 成本监控工具
- [ ] 健康检查脚本

### 测试和文档
- [ ] 完整的AI模块测试套件
- [ ] Mock提供商测试实现
- [ ] API使用文档和示例
- [ ] 提示词工程指南

## 风险与缓解

### 高风险项
1. **API成本控制**: AI调用费用可能超出预算
   - **缓解**: 实现Token使用限制和成本监控
   - **备选**: 优先使用本地模型和缓存机制

2. **API稳定性**: 第三方AI服务可能不稳定
   - **缓解**: 多提供商故障转移和本地备选
   - **监控**: 实时健康检查和错误监控

### 中风险项
1. **提示词质量**: 提示词设计影响分析质量
   - **缓解**: 基于测试数据优化提示词
   - **验证**: 建立AI分析质量评估机制

---
**任务负责人**: AI Engineer  
**审核人**: Security Expert  
**依赖任务**: Task 001, 002  
**预计工作量**: 3天  
**关键里程碑**: AI集成完成，漏洞分析可用